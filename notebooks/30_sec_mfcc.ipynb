{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d88301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATASET_PATH = '../data/audio/BanglaBeats'  # REPLACE with your actual folder path\n",
    "GENRES = ['Adhunik', 'Folk', 'Hiphop', 'Indie', 'Islamic', 'Metal', 'Pop', 'Rock']\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION_CHUNKS = 10  # Number of 3s clips to make one 30s clip\n",
    "\n",
    "def extract_features(y, sr, filename, label):\n",
    "    \"\"\"\n",
    "    Extracts all specific features requested for the GTZAN-style CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Basic Audio Processing\n",
    "    # Harmonic and Percussive components\n",
    "    y_harm, y_perc = librosa.effects.hpss(y)\n",
    "    \n",
    "    # 2. Spectral Features\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    \n",
    "    # 3. Tempo\n",
    "    # librosa > 0.10.0 returns tempo as a scalar or array depending on aggregators\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    if isinstance(tempo, np.ndarray):\n",
    "        tempo = tempo[0] # Handle array return in newer librosa versions\n",
    "\n",
    "    # 4. MFCCs (20 coefficients)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    # --- BUILD FEATURE DICTIONARY ---\n",
    "    # We calculate Mean and Variance for each feature\n",
    "    features = {\n",
    "        \"filename\": filename,\n",
    "        \"length\": len(y),\n",
    "        \n",
    "        \"chroma_stft_mean\": np.mean(chroma_stft),\n",
    "        \"chroma_stft_var\": np.var(chroma_stft),\n",
    "        \n",
    "        \"rms_mean\": np.mean(rms),\n",
    "        \"rms_var\": np.var(rms),\n",
    "        \n",
    "        \"spectral_centroid_mean\": np.mean(spec_cent),\n",
    "        \"spectral_centroid_var\": np.var(spec_cent),\n",
    "        \n",
    "        \"spectral_bandwidth_mean\": np.mean(spec_bw),\n",
    "        \"spectral_bandwidth_var\": np.var(spec_bw),\n",
    "        \n",
    "        \"rolloff_mean\": np.mean(rolloff),\n",
    "        \"rolloff_var\": np.var(rolloff),\n",
    "        \n",
    "        \"zero_crossing_rate_mean\": np.mean(zcr),\n",
    "        \"zero_crossing_rate_var\": np.var(zcr),\n",
    "        \n",
    "        \"harmony_mean\": np.mean(y_harm),\n",
    "        \"harmony_var\": np.var(y_harm),\n",
    "        \n",
    "        \"perceptr_mean\": np.mean(y_perc),\n",
    "        \"perceptr_var\": np.var(y_perc),\n",
    "        \n",
    "        \"tempo\": tempo,\n",
    "    }\n",
    "\n",
    "    # Add MFCCs (1 through 20)\n",
    "    for i in range(20):\n",
    "        features[f\"mfcc{i+1}_mean\"] = np.mean(mfcc[i])\n",
    "        features[f\"mfcc{i+1}_var\"] = np.var(mfcc[i])\n",
    "\n",
    "    features[\"label\"] = label\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    data_rows = []\n",
    "\n",
    "    print(f\"Processing dataset at: {DATASET_PATH}...\")\n",
    "\n",
    "    for genre in GENRES:\n",
    "        genre_path = os.path.join(DATASET_PATH, genre)\n",
    "        \n",
    "        if not os.path.exists(genre_path):\n",
    "            print(f\"Skipping {genre} (Folder not found)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing genre: {genre}\")\n",
    "        \n",
    "        # Get all wav files\n",
    "        files = glob.glob(os.path.join(genre_path, \"*.wav\"))\n",
    "        \n",
    "        # CRITICAL: Sort files numerically (1.wav, 2.wav, ... 10.wav)\n",
    "        # Otherwise '10.wav' might come before '2.wav' in string sort\n",
    "        try:\n",
    "            files.sort(key=lambda f: int(os.path.basename(f).split('.')[0]))\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Non-numeric filenames found in {genre}. Sorting alphabetically.\")\n",
    "            files.sort()\n",
    "\n",
    "        # Chunk files into groups of 10\n",
    "        # Files 1-10 -> Song 1\n",
    "        # Files 11-20 -> Song 2\n",
    "        for i in range(0, len(files), DURATION_CHUNKS):\n",
    "            chunk_files = files[i : i + DURATION_CHUNKS]\n",
    "            \n",
    "            # Ensure we have a full 30-second set (optional check)\n",
    "            if len(chunk_files) < DURATION_CHUNKS:\n",
    "                print(f\"  Skipping incomplete chunk at index {i} in {genre}\")\n",
    "                continue\n",
    "\n",
    "            # Load and Concatenate\n",
    "            combined_y = []\n",
    "            for wav_file in chunk_files:\n",
    "                y, _ = librosa.load(wav_file, sr=SAMPLE_RATE)\n",
    "                combined_y.append(y)\n",
    "            \n",
    "            # Stitch the 10 parts into one array\n",
    "            y_30s = np.concatenate(combined_y)\n",
    "            \n",
    "            # Define a filename for the CSV (e.g., \"adhunik.00001.wav\")\n",
    "            # We use the name of the first file in the chunk to generate an ID\n",
    "            song_id = (i // DURATION_CHUNKS)\n",
    "            csv_filename = f\"{genre}.{song_id:05d}.wav\"\n",
    "\n",
    "            # Extract Features\n",
    "            row_data = extract_features(y_30s, SAMPLE_RATE, csv_filename, genre)\n",
    "            data_rows.append(row_data)\n",
    "\n",
    "    # --- EXPORT TO CSV ---\n",
    "    # Define exact column order as requested\n",
    "    columns = [\n",
    "        \"filename\", \"length\", \n",
    "        \"chroma_stft_mean\", \"chroma_stft_var\",\n",
    "        \"rms_mean\", \"rms_var\",\n",
    "        \"spectral_centroid_mean\", \"spectral_centroid_var\",\n",
    "        \"spectral_bandwidth_mean\", \"spectral_bandwidth_var\",\n",
    "        \"rolloff_mean\", \"rolloff_var\",\n",
    "        \"zero_crossing_rate_mean\", \"zero_crossing_rate_var\",\n",
    "        \"harmony_mean\", \"harmony_var\",\n",
    "        \"perceptr_mean\", \"perceptr_var\",\n",
    "        \"tempo\"\n",
    "    ]\n",
    "    # Add MFCC columns dynamically to ensure correct order 1-20\n",
    "    for i in range(1, 21):\n",
    "        columns.append(f\"mfcc{i}_mean\")\n",
    "        columns.append(f\"mfcc{i}_var\")\n",
    "    \n",
    "    columns.append(\"label\")\n",
    "\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    # Reorder columns to match GTZAN strictly\n",
    "    df = df[columns]\n",
    "    \n",
    "    output_file = \"banglabeats_features_30sec.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Done! Saved features to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
